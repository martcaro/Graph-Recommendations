{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import operator\n",
    "# Documentacion de la libreria: http://networkx.readthedocs.io/en/networkx-1.11/\n",
    "\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS \n",
    "\n",
    "# DATASET_SIZE = 100000\n",
    "DATASET_SIZE =  15954 # most popular movies 200 && users que han interactuado con 50%\n",
    "# DATASET_SIZE =  34030 # most popular movies 200 && users que han interactuado con 25%\n",
    "# DATASET_SIZE =  42482 # most popular movies 200 && users que han interactuado con 12.5%\n",
    "\n",
    "# HALF_DATASET_SIZE = int(90*DATASET_SIZE / 100)\n",
    "# HALF_DATASET_SIZE = int(75*DATASET_SIZE / 100)\n",
    "# SECOND_HALF_DATASET = int(DATASET_SIZE - HALF_DATASET_SIZE)\n",
    "RATING_THRESHOLD = 4\n",
    "WEIGHT_THRESHOLD = 5\n",
    "# K = 10\n",
    "K = 3\n",
    "range_K = [3,5,10]\n",
    "MEASURES = ['aa', 'cn', 'ew', 'jn', 'pa', 'waa', 'wcn', 'wpa']\n",
    "USERS_EVAL = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareNodes(f_list, s_list):\n",
    "    \"\"\"\n",
    "        Function that returns the number of users that have interact with both items\n",
    "        Funcion que devuelve el numero de usuarios que han interactuado con ambos items\n",
    "    \"\"\"\n",
    "    peso = len(np.intersect1d(f_list, s_list))\n",
    "    \n",
    "    return peso\n",
    "    \n",
    "def createLinks(prob_us_set, nodos, threshold):\n",
    "    \"\"\"\n",
    "        Function that creates graph links with the information about the set. The weight has to be grater or equal to threshold.\n",
    "        \n",
    "        Funcion que crea los enlaces del grafo a partir de la informacion contenida en el conjunto que se le\n",
    "        pasa a la funcion. El peso tiene que ser mayor o igual al umbral.\n",
    "        \n",
    "        Format of links list -> [(Node1, Node2, weight), ......]\n",
    "    \"\"\"\n",
    "    resultado = list() \n",
    "    \n",
    "    # hago todas las posibles combinaciones de problemas\n",
    "    for fst, snd in it.combinations(nodos, 2):\n",
    "        # obtengo el peso pasando la lista de usuarios que ha hecho cada problema\n",
    "        peso = compareNodes(prob_us_set[fst], prob_us_set[snd])\n",
    "        if peso >= threshold:\n",
    "            resultado.append((fst, snd, peso))\n",
    "            \n",
    "            \n",
    "            \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_nx(list_nodes, list_links):\n",
    "    \"\"\"\n",
    "        Function that creates a graph with the format from NetworkX \n",
    "        \n",
    "        Funcion que crea un grafo de tipo Graph de la libreria NetworkX\n",
    "        Construccion del grafo: http://networkx.readthedocs.io/en/networkx-1.11/tutorial/tutorial.html#what-to-use-as-nodes-and-edges\n",
    "    \"\"\"\n",
    "    grafo = nx.Graph() # creo la variable grafo\n",
    "\n",
    "    # incluyo los nodos del grafo \n",
    "    grafo.add_nodes_from(list_nodes)\n",
    "\n",
    "    # se incluyen las tuplas de enlaces con el peso del enlace\n",
    "    # es una lista de la forma [(Nodo1, Nodo2, peso), ......]\n",
    "    grafo.add_weighted_edges_from(list_links)\n",
    "\n",
    "    return grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_connected(u, v, graph):\n",
    "    return u in graph.neighbors(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areAccessibleUser(current_user, possible, graph):\n",
    "    access = [p for p in possible if nodes_connected(current_user, p, graph)]\n",
    "    return list(set(access))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def areAccessible(possible, acc_users, df_users_simple):\n",
    "    \"\"\"\n",
    "        Function that check if at least one user in acc_users has interacted with each item in possible\n",
    "    \"\"\"\n",
    "    access = list()\n",
    "    for p in possible:\n",
    "        encontrado = False\n",
    "        cont = 0\n",
    "        while (cont < len(acc_users)) and (encontrado == False):\n",
    "            if p in df_users_simple[acc_users[cont]]:\n",
    "                access.append(p)\n",
    "                encontrado = True\n",
    "            else:\n",
    "                cont = cont + 1\n",
    "    \n",
    "    return list(set(access)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_aa(i1, i2, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve para cada par de nodos, el sumatorio de 1/log(N(z)), siendo N(z) el grado del nodo z para todo z \n",
    "        perteneciente al conjunto de nodos en comun de ese par de nodos\n",
    "    \"\"\"\n",
    "    \n",
    "    # obtengo un iterador de un solo elemento que tiene en la tercera posicion el valor de AA para el par de nodos\n",
    "    value = nx.adamic_adar_index(graph, [(i1, i2)])\n",
    "    \n",
    "    value_aa = 0\n",
    "    for u, v, p in value:\n",
    "        # itero el iterador, guardando el valor de adar adamic\n",
    "        value_aa = p\n",
    "    \n",
    "    return value_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cn(i1, i2, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el numero de vecinos en comun de esos dos nodos\n",
    "    \"\"\"\n",
    "    return len(list(nx.common_neighbors(graph, i1, i2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ew(fst, snd, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el peso del enlace en cada par\n",
    "    \"\"\"\n",
    "    \n",
    "    weight = graph.get_edge_data(fst, snd)\n",
    "    \n",
    "    # print(weight)\n",
    "    \n",
    "    if weight == None: # devuelve 0 en caso de que no exista enlace\n",
    "        return 0\n",
    "    else: # si si existe, devuelve el peso\n",
    "        return weight['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_jn(i1, i2, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el numero de vecinos en comun de esos dos nodos\n",
    "    \"\"\"\n",
    "    values_jn = nx.jaccard_coefficient(graph, [(i1, i2)])\n",
    "    \n",
    "    value_jn = 0\n",
    "    for u, v, p in values_jn:\n",
    "        value_jn = p # saco el valor\n",
    "        \n",
    "    return value_jn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pa(i1, i2, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el valor de preferential attachment\n",
    "    \"\"\"\n",
    "    values_pa = nx.preferential_attachment(graph, [(i1, i2)])\n",
    "    \n",
    "    value_pa = 0\n",
    "    for u, v, p in values_pa:\n",
    "        value_pa = p # saco el valor\n",
    "        \n",
    "    return value_pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_waa(i1, i2, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve para cada par de nodos, el valor de weighted adar adamic\n",
    "    \"\"\"\n",
    "    \n",
    "    # primero tengo que calcular los common neighbors de ambos items\n",
    "    cn_list = nx.common_neighbors(graph, i1, i2)\n",
    "    \n",
    "    # ahora tengo que hacer el sumatorio del valor para cada elemento de cn_list\n",
    "    value_waa = sum([((graph[i1][x]['weight'] + graph[i2][x]['weight']) / math.log(1 + graph.degree(x, weight=\"weight\"), 10) )  for x in cn_list])    \n",
    "    \n",
    "    \n",
    "    return value_waa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wcn(i1, i2, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el numero de vecinos en comun de esos dos nodos\n",
    "    \"\"\"\n",
    "    cn_list = nx.common_neighbors(graph, i1, i2)\n",
    "    \n",
    "    value_wcn = sum([graph[i1][x]['weight'] + graph[i2][x]['weight'] for x in cn_list])\n",
    "    \n",
    "    return value_wcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wpa(i1, i2, graph):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve el valor de weighted preferential attachment\n",
    "    \"\"\"\n",
    "    value_wpa = graph.degree(i1, weight=\"weight\") * graph.degree(i2, weight=\"weight\")\n",
    "        \n",
    "    return value_wpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_measure(i1, i2, graph, measure):\n",
    "     \n",
    "    \"\"\"\n",
    "        Function that resturn similarity value with the measure\n",
    "        \n",
    "    \"\"\"\n",
    "    # Aplico la funcion a cada fila\n",
    "    if measure == 'aa':\n",
    "        sim_result = apply_aa(i1, i2, graph)\n",
    "    elif measure == 'cn':\n",
    "        sim_result = apply_cn(i1, i2, graph)\n",
    "    elif measure == 'ew':\n",
    "        sim_result = apply_ew(i1, i2, graph)\n",
    "    elif measure == 'jn':    \n",
    "        sim_result = apply_jn(i1, i2, graph)\n",
    "    elif measure == 'pa':    \n",
    "        sim_result = apply_pa(i1, i2, graph)\n",
    "\n",
    "    elif measure == 'waa':\n",
    "        sim_result = apply_waa(i1, i2, graph)\n",
    "    elif measure == 'wcn':    \n",
    "        sim_result = apply_wcn(i1, i2, graph)\n",
    "    elif measure == 'wpa':    \n",
    "        sim_result = apply_wpa(i1, i2, graph)\n",
    "        \n",
    "    return sim_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix_users(users, graph, user):\n",
    "    \"\"\" en cada fila, voy a tener el conjunto de users a evaluar\n",
    "        en las columnas, todos los users del grafo\"\"\"\n",
    "    \n",
    "    if not os.path.exists('similarities/user_weig_50/user_' + str(user) + '/'):\n",
    "        os.makedirs('similarities/user_weig_50/user_' + str(user) + '/')\n",
    "                          \n",
    "    for measure in MEASURES:\n",
    "        with open('similarities/user_weig_50/user_' + str(user) + '/user_' + measure + '.csv', 'w') as result_file:\n",
    "            print('user1,user2,similarity', file=result_file)\n",
    "\n",
    "            for u in users:\n",
    "                sim = apply_measure(user, u, graph, measure)\n",
    "                print(f\"{user},{u},{sim}\", file=result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_sim_matrix(user):\n",
    "    \"\"\" Read the arrays\"\"\"\n",
    "    pd_sim_aa = pd.read_csv('similarities/user_weig_50/user_' + str(user) + '/user_aa.csv')\n",
    "    pd_sim_cn = pd.read_csv('similarities/user_weig_50/user_' + str(user) + '/user_cn.csv')\n",
    "    pd_sim_ew = pd.read_csv('similarities/user_weig_50/user_' + str(user) + '/user_ew.csv')\n",
    "    pd_sim_jn = pd.read_csv('similarities/user_weig_50/user_' + str(user) + '/user_jn.csv')\n",
    "    pd_sim_pa = pd.read_csv('similarities/user_weig_50/user_' + str(user) + '/user_pa.csv')\n",
    "    pd_sim_waa = pd.read_csv('similarities/user_weig_50/user_' + str(user) + '/user_waa.csv')\n",
    "    pd_sim_wcn = pd.read_csv('similarities/user_weig_50/user_' + str(user) + '/user_wcn.csv')\n",
    "    pd_sim_wpa = pd.read_csv('similarities/user_weig_50/user_' + str(user) + '/user_wpa.csv')\n",
    "\n",
    "\n",
    "    sim_aa = pd_sim_aa.pivot(index='user1', columns='user2', values='similarity')\n",
    "    sim_cn = pd_sim_cn.pivot(index='user1', columns='user2', values='similarity')\n",
    "    sim_ew = pd_sim_ew.pivot(index='user1', columns='user2', values='similarity')\n",
    "    sim_jn = pd_sim_jn.pivot(index='user1', columns='user2', values='similarity')\n",
    "    sim_pa = pd_sim_pa.pivot(index='user1', columns='user2', values='similarity')\n",
    "    sim_waa = pd_sim_waa.pivot(index='user1', columns='user2', values='similarity')\n",
    "    sim_wcn = pd_sim_wcn.pivot(index='user1', columns='user2', values='similarity')\n",
    "    sim_wpa = pd_sim_wpa.pivot(index='user1', columns='user2', values='similarity')\n",
    "    \n",
    "    return sim_aa, sim_cn, sim_ew, sim_jn, sim_pa, sim_waa, sim_wcn, sim_wpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delRepetitions(lista):\n",
    "    \"\"\"\n",
    "        Funcion auxiliar para evitar que salgan repeticiones en las recomendaciones. Saco la lista de posibles \n",
    "        recomendaciones con valores unicos\n",
    "    \"\"\"\n",
    "    conjunto_vacio = set()\n",
    "    \n",
    "    # esto sirve para que se haga mas rapido la comprobacion de si el elemento esta en la lista o no\n",
    "    function_add = conjunto_vacio.add\n",
    "    \n",
    "    # hago la lista intensional, para mantener el orden dado en la lista original\n",
    "    return [x for x in lista if not (x in conjunto_vacio or function_add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeighing(item, items_recom_with_values):\n",
    "    weight = sum([value for (it, value) in items_recom_with_values if it == item])\n",
    "    \n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_recommendations(user, recom_list, measure):        \n",
    "    f = open('recommendations/user_weighted-vot_recoms_50.csv', 'a')\n",
    "    f.write(str(user) + ',' + measure + ',' + str(recom_list) + '\\n') \n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKrecommendations(row, df_users, k, measure, users):\n",
    "    \"\"\"\n",
    "        Funcion que devuelve la lista de k mejores problemas para el usuario dado teniendo en cuenta que \n",
    "        las recomendaciones no son items con los que haya interactuado el usuario\n",
    "    \"\"\"\n",
    "    \n",
    "    my_user = row['user_id']\n",
    "    \n",
    "    # obtengo los usuarios que tienen un valor de similitud mayor que cero\n",
    "    sim_users = [u for u in users if measure[u][my_user] > 0]\n",
    "    sim_users_values = [measure[u][my_user] for u in users if measure[u][my_user] > 0]\n",
    "    total = sum(sim_users_values)\n",
    "    \n",
    "    # obtengo los items con los que han interactuado los usuarios similares\n",
    "    items_recom_with_values = [(item, measure[u][my_user]) for u in sim_users for item in df_users[u] ]\n",
    "    items_recom_no_values = list(set([item for (item, _) in items_recom_with_values]))\n",
    "    \n",
    "    # Sistema de votaciÃ³n ponderada: para cada item que aparezca, sumar todos sus valores de similitud asociado / total\n",
    "    items_recom = [(item, getWeighing(item, items_recom_with_values)/total) for item in items_recom_no_values]\n",
    "    \n",
    "    items_recom.sort(key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    # y me quedo con el primer elemento de la tupla, que es el item a recomendar\n",
    "    list_sim_final = [x for (x,_) in items_recom] \n",
    "        \n",
    "    # ahora elimino los items que estan en la lista de items con los que ha interactuado el target user\n",
    "    list_final = [x for x in list_sim_final if x not in df_users[my_user]]\n",
    "    \n",
    "    # y quito las repeticiones\n",
    "    list_final = delRepetitions(list_final)\n",
    "    \n",
    "    list_fin_rec = [x for x in list_final if x in items_eval]\n",
    "    \n",
    "    return list_fin_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_getKrecommendations(df_new, df_users, k, measure, users, items_eval, user, my_measure):\n",
    "    \"\"\"\n",
    "    Function to generate a new column with the list of recommendations for each user\n",
    "    \"\"\"\n",
    "\n",
    "    df_new['recommendation_original'] = df_new.apply(lambda row: getKrecommendations(row, df_users, k, measure, users), axis=1)\n",
    "    df_new['recommendation'] = df_new.apply(lambda row: row['recommendation_original'][:k], axis=1)    \n",
    "        \n",
    "    if k == 10:\n",
    "        df_new.apply(lambda row: write_recommendations(user, row['recommendation_original'], my_measure), axis=1)\n",
    "        \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMetricsResults(list_recom_items, list_recom_items_original, user_list_to_recommend, list_eval_items, list_rel_accessible, k):    \n",
    "    set_df_metric = {'user_id': user_list_to_recommend, 'eval_items': list_eval_items, 'recom_items': list_recom_items, 'rel_accessible': list_rel_accessible, 'recom_items_original': list_recom_items_original}\n",
    "    metric_df = pd.DataFrame.from_dict(set_df_metric)\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hit(row):\n",
    "    \"\"\"\n",
    "        Funcion que implementa la metrica one hit. Devuelve un 1 si para un usuario dado, ese usuario ha interactuado \n",
    "        con al menos uno de los items que se le ha recomendado en el evaluation_set. \n",
    "        Cero si no hay ningun item de los recomendados con los que el usuario haya interactuado\n",
    "    \"\"\"\n",
    "    num_items_common = np.intersect1d(row['recom_items'], row['eval_items'])\n",
    "    \n",
    "    if len(num_items_common) >= 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(row): \n",
    "    \"\"\"\n",
    "        Funcion que va a implementar la metrica de evaluacion mrr:\n",
    "        mrr = 1/ranki, donde ranki es la posicion del primer item correcto\n",
    "    \"\"\"\n",
    "\n",
    "    num_items_common = np.intersect1d(row['recom_items'], row['eval_items'])\n",
    "    \n",
    "    if len(num_items_common) >= 1:\n",
    "\n",
    "        # hago la busqueda del primer elemento que esta en la lista de recomendados\n",
    "        fst_correct_item = -1\n",
    "        encontrado = False\n",
    "        i = 0\n",
    "        ranki = 0\n",
    "        #print(ranki)\n",
    "        while (i < len(row['recom_items'])) and (encontrado == False):\n",
    "            if row['recom_items'][i] in row['eval_items']:\n",
    "                # fst_correct_item = row['recom_items'][i]\n",
    "                # print(fst_correct_item)\n",
    "                ranki = i + 1\n",
    "                encontrado = True\n",
    "                #print(\"entro\")\n",
    "            else:\n",
    "                i = i + 1\n",
    "                \n",
    "        if ranki == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return (1/ranki)\n",
    "\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(row):\n",
    "    \"\"\"\n",
    "        Funcion que va a implementar la metrica precision en k: \n",
    "        (cuantos de los interactuados con el usuario estan entre los recomendados) / todos los recomendados\n",
    "    \"\"\"\n",
    "    \n",
    "    num_items_common = np.intersect1d(row['recom_items'], row['eval_items'])\n",
    "    \n",
    "    # print(num_items_common)\n",
    "    \n",
    "    return (len(num_items_common)/len(row['recom_items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(row):\n",
    "    \"\"\"\n",
    "        Funcion que implementa la metrica recall\n",
    "        (cuantos de los interactuados con el usuario estan entre los recomendados) / todos los evaluados\n",
    "    \"\"\"\n",
    "    num_items_common = np.intersect1d(row['recom_items'], row['eval_items'])\n",
    "    \n",
    "    # print(num_items_common)\n",
    "    \n",
    "    return (len(num_items_common)/len(row['eval_items']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(row):\n",
    "    \"\"\"\n",
    "        Funcion que calcula el f1 en funcion de precision y recall\n",
    "    \"\"\"\n",
    "    denominador = row['precision'] + row['recall']\n",
    "    \n",
    "    if denominador == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * row['precision'] * row['recall']) / denominador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rPrecision(row):\n",
    "    \"\"\"\n",
    "        Funcion que va a implementar la metrica r-precision: cuales de los recomendados \n",
    "        son relevantes en el conjunto de accesibles por el grafo \n",
    "    \"\"\"\n",
    "    if len(row['rel_accessible']) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        recomendations = row['recom_items_original'][:len(row['rel_accessible'])]\n",
    "        num_items_common = np.intersect1d(recomendations, row['rel_accessible'])\n",
    "\n",
    "        # print(num_items_common)\n",
    "\n",
    "        return (len(num_items_common)/len(row['rel_accessible']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateScoreResults(metric_df):\n",
    "    \"\"\"\n",
    "        Function to build a dataframe with the results for the evaluation metrics\n",
    "    \"\"\"\n",
    "    metric_df['one_hit'] = metric_df.apply(lambda row: one_hit(row), axis=1)\n",
    "    metric_df['mrr'] = metric_df.apply(lambda row: mrr(row), axis=1)\n",
    "    metric_df['precision'] = metric_df.apply(lambda row: precision(row), axis=1)\n",
    "    metric_df['recall'] = metric_df.apply(lambda row: recall(row), axis=1)\n",
    "    metric_df['f1'] = metric_df.apply(lambda row: f1(row), axis=1)\n",
    "    metric_df['rprec'] = metric_df.apply(lambda row: rPrecision(row), axis=1)\n",
    "\n",
    "    result_one_hit = metric_df['one_hit'].mean()\n",
    "    result_precision = metric_df['precision'].mean()\n",
    "    result_mrr = metric_df['mrr'].mean()\n",
    "    result_recall = metric_df['recall'].mean()\n",
    "    result_f1 = metric_df['f1'].mean()\n",
    "    result_rprec = metric_df['rprec'].mean()\n",
    "\n",
    "    # voy a crear un diccionario con los resultados\n",
    "    results_metrics = {'one_hit': result_one_hit, 'precision': result_precision, 'mrr': result_mrr, 'recall': result_recall, 'f1': result_f1, 'rprec': result_rprec}\n",
    "    # results_metrics = {'rprec': result_rprec}\n",
    "\n",
    "    \n",
    "    return results_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_process(user, items_eval):\n",
    "    training_set = pd.read_csv('user-datasets-50/user_' + str(user) + '_training.csv')\n",
    "    evaluation_set = pd.read_csv('user-datasets-50/user_' + str(user) + '_test.csv')\n",
    "\n",
    "    # I get the list of nodes\n",
    "    nodes = training_set.user.unique()\n",
    "    print(len(nodes))\n",
    "\n",
    "    # I create a dictionary: keys are the items, and values are the list of users that are interacted with this item\n",
    "    grouped = training_set.groupby('user')['item'].apply(list)\n",
    "\n",
    "    # I create the links with the suitable format for nx\n",
    "    links = createLinks(grouped, nodes, WEIGHT_THRESHOLD)\n",
    "    print(len(links))\n",
    "\n",
    "    ##################### GRAPH CREATION\n",
    "    # I create the graph\n",
    "    graph = create_graph_nx(nodes, links)\n",
    "    \n",
    "    # diccionario que va a contener como key el user, como value, los items con los que ha interactuado el user\n",
    "    df_users_simple = {}\n",
    "    grouped_user = training_set.groupby('user')['item'].apply(list)\n",
    "    for i,j in zip(grouped_user.index.tolist(), grouped_user.values.tolist()):\n",
    "        df_users_simple[i] = j \n",
    "        \n",
    "    # PARA LA CONSTRUCCION DE R PRECISION -----------\n",
    "    grouped_user_eval = evaluation_set.groupby('user')['item'].apply(list)\n",
    "\n",
    "    # convierto la serie en un dataframe\n",
    "    df_users_eval = pd.DataFrame({'user_id':grouped_user_eval.index, 'list_item_id':grouped_user_eval.values})\n",
    "\n",
    "    user_list_to_recommend = list(evaluation_set.user.unique())\n",
    "\n",
    "    # hago el filtro para los usuarios a los que tengo que recomendar\n",
    "    df_users_eval = df_users_eval[df_users_eval['user_id'].isin(user_list_to_recommend)]\n",
    "    # primero voy a ordenar la lista de usuarios a recomendar\n",
    "    user_list_to_recommend.sort()\n",
    "    list_eval_items = df_users_eval['list_item_id'].tolist()\n",
    "\n",
    "    df_users_eval[\"user_accessible\"] = df_users_eval.apply (lambda row: areAccessibleUser(row['user_id'], list(nodes), graph), axis=1)\n",
    "    df_users_eval[\"rel_accessible\"] = df_users_eval.apply (lambda row: areAccessible(row['list_item_id'], row['user_accessible'], graph), axis=1)\n",
    "    df_users_eval[\"num_accessible\"] = df_users_eval.apply (lambda row: len(row['rel_accessible']), axis=1)\n",
    "    list_rel_accessible = df_users_eval['rel_accessible'].tolist()\n",
    "    list_eval_items = df_users_eval['list_item_id'].tolist()\n",
    "    user_list_to_recommend = df_users_eval['user_id'].tolist()\n",
    "    \n",
    "    # construccion de matrices de similitud\n",
    "    build_matrix_users(nodes, graph, user)\n",
    "\n",
    "    sim_aa, sim_cn, sim_ew, sim_jn, sim_pa, sim_waa, sim_wcn, sim_wpa = getting_sim_matrix(user)\n",
    "    list_measures = [sim_aa, sim_cn, sim_ew, sim_jn, sim_pa, sim_waa, sim_wcn, sim_wpa]\n",
    "\n",
    "    # creo el nuevo dataframe con los resultados \n",
    "    column_user_recomend = {'user_id': user_list_to_recommend}\n",
    "    dataframe_user_recomend = pd.DataFrame.from_dict(column_user_recomend)\n",
    "\n",
    "    dataframe_k_measures_original = list()\n",
    "\n",
    "    dataframe_k_measures_original = [[apply_getKrecommendations(dataframe_user_recomend, df_users_simple, k, list_measures[MEASURES.index(measure)], nodes, items_eval, user, measure).copy() for measure in MEASURES] for k in range_K]\n",
    "    metrics_results = [[calculateMetricsResults(dataframe_k_measures_original[k][MEASURES.index(measure)]['recommendation'].tolist(), dataframe_k_measures_original[k][MEASURES.index(measure)]['recommendation_original'].tolist(), user_list_to_recommend, list_eval_items, list_rel_accessible, range_K[k]) for measure in MEASURES] for k in range(K)]\n",
    "\n",
    "    return metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_file(dir, result, k, measure):\n",
    "    f = open(dir, 'a')\n",
    "    f.write(str(k) + ',' + measure + ',' + str(result['one_hit']) + ',' + str(result['precision']) + ',' + str(result['mrr']) + ',' + str(result['recall']) + ',' +  str(result['f1']) + ',' +  str(result['rprec']) + '\\n') \n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user  item  rating  timestamp\n",
      "0       305   451       3  886324817\n",
      "1        62   257       2  879372434\n",
      "2       194   274       2  879539794\n",
      "3       299   144       4  877881320\n",
      "4       308     1       4  887736532\n",
      "...     ...   ...     ...        ...\n",
      "15949   864   685       4  888891900\n",
      "15950   279    64       1  875308510\n",
      "15951   660   229       2  891406212\n",
      "15952   880   476       3  880175444\n",
      "15953   716   204       5  879795543\n",
      "\n",
      "[15954 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('most_pop_200_users.csv')\n",
    "\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user  item  rating  timestamp\n",
      "3590    276   258       5  874786337\n",
      "15845   276   300       4  874786338\n",
      "7398    276   328       4  874786366\n",
      "145     276   294       4  874786366\n",
      "2449    276   288       4  874786392\n",
      "...     ...   ...     ...        ...\n",
      "9791    796   393       4  893218933\n",
      "9546    796   419       5  893219001\n",
      "15928   407     7       4  893253637\n",
      "6835    653   272       4  893275949\n",
      "12346   653   245       4  893276091\n",
      "\n",
      "[15954 rows x 4 columns]\n",
      "200\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values('timestamp')\n",
    "\n",
    "print(df)\n",
    "\n",
    "users = df.user.unique()\n",
    "items = df.item.unique()\n",
    "num_items = len(items)\n",
    "num_users = len(users)\n",
    "\n",
    "print(num_items)\n",
    "print(num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_eval = sorted([508,240,273,274,9,451,286,313,411,180,1,153,179,588,187,259,582,527])\n",
    "len(items_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users = [1, 2, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 28, 30, 32, 37, 38, 41, 42, 43, 44, 45, 48, 49, 52, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 87, 89, 90, 91, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 106, 108, 109, 110, 113, 114, 115, 116, 117, 118, 119, 121, 123, 125, 128, 130, 135, 137, 138, 141, 144, 145, 148, 151, 152, 154, 157, 158, 159, 160, 161, 162, 164, 168, 174, 175, 177, 178, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 197, 198, 200, 201, 207, 210, 213, 214, 215, 216, 217, 218, 221, 222, 223, 224, 226, 227, 230, 232, 233, 234, 235, 236, 237, 239, 243, 244, 246, 248, 249, 250, 251, 253, 254, 255, 256, 259, 262, 263, 264, 265, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 279, 280, 283, 286, 287, 288, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 301, 303, 305, 307, 308, 311, 312, 313, 314, 315, 316, 318, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 332, 334, 336, 338, 339, 340, 342, 343, 344, 345, 346, 347, 348, 350, 352, 354, 357, 360, 361, 363, 365, 370, 371, 372, 373, 374, 378, 379, 380, 381, 382, 383, 385, 387, 388, 389, 391, 392, 393, 394, 395, 396, 397, 398, 399, 401, 402, 403, 405, 406, 407, 409, 411, 412, 413, 416, 417, 421, 422, 423, 424, 425, 426, 429, 430, 432, 433, 435, 436, 437, 442, 445, 447, 449, 450, 452, 453, 454, 455, 456, 457, 458, 459, 460, 463, 464, 465, 466, 468, 470, 472, 474, 476, 478, 479, 480, 481, 483, 484, 486, 487, 488, 489, 490, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 503, 504, 505, 506, 507, 508, 514, 518, 521, 523, 524, 525, 526, 527, 528, 530, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 545, 548, 551, 552, 553, 554, 555, 556, 559, 560, 561, 562, 566, 567, 568, 569, 573, 576, 577, 579, 582, 586, 587, 588, 590, 591, 592, 593, 595, 600, 601, 603, 605, 606, 608, 610, 615, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 629, 630, 632, 633, 634, 637, 638, 639, 640, 642, 643, 645, 647, 648, 650, 653, 654, 655, 658, 659, 660, 661, 663, 664, 665, 666, 667, 668, 669, 670, 671, 674, 676, 677, 679, 680, 682, 683, 684, 686, 690, 692, 693, 694, 697, 698, 699, 703, 704, 705, 707, 708, 709, 710, 711, 712, 714, 715, 716, 717, 719, 721, 724, 727, 731, 733, 734, 735, 738, 739, 741, 745, 746, 747, 748, 749, 751, 753, 756, 757, 758, 759, 761, 763, 764, 766, 768, 770, 771, 773, 774, 776, 777, 778, 779, 780, 781, 782, 786, 788, 790, 793, 795, 796, 798, 802, 804, 805, 806, 807, 815, 821, 823, 825, 826, 829, 830, 831, 833, 834, 835, 836, 837, 838, 839, 840, 843, 844, 846, 847, 848, 850, 851, 852, 854, 860, 862, 864, 865, 867, 868, 870, 871, 872, 875, 877, 878, 880, 881, 882, 883, 885, 886, 887, 889, 890, 892, 893, 894, 896, 897, 899, 901, 902, 903, 905, 907, 908, 910, 911, 912, 913, 916, 918, 919, 921, 922, 923, 924, 927, 929, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 942, 943]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current user: 1---276------\n",
      "129\n",
      "8215\n",
      "Current user: 2---532------\n",
      "129\n",
      "8215\n",
      "Current user: 3---130------\n",
      "129\n",
      "8215\n",
      "Current user: 4---297------\n",
      "129\n",
      "8215\n",
      "Current user: 5---1------\n",
      "129\n",
      "8215\n",
      "Current user: 6---833------\n",
      "129\n",
      "8214\n",
      "Current user: 7---407------\n",
      "129\n",
      "8215\n",
      "Current user: 8---870------\n",
      "129\n",
      "8215\n",
      "Current user: 9---279------\n",
      "129\n",
      "8215\n",
      "Current user: 10---145------\n",
      "129\n",
      "8215\n",
      "Current user: 11---919------\n",
      "129\n",
      "8215\n",
      "Current user: 12---268------\n",
      "129\n",
      "8215\n",
      "Current user: 13---514------\n",
      "129\n",
      "8215\n",
      "Current user: 14---207------\n",
      "129\n",
      "8215\n",
      "Current user: 15---92------\n",
      "129\n",
      "8215\n",
      "Current user: 16---286------\n",
      "129\n",
      "8215\n",
      "Current user: 17---102------\n",
      "129\n",
      "8214\n",
      "Current user: 18---43------\n",
      "129\n",
      "8215\n",
      "Current user: 19---472------\n",
      "129\n",
      "8215\n",
      "Current user: 20---886------\n",
      "129\n",
      "8215\n",
      "Current user: 21---343------\n",
      "129\n",
      "8215\n",
      "Current user: 22---881------\n",
      "129\n",
      "8215\n",
      "Current user: 23---416------\n",
      "129\n",
      "8215\n",
      "Current user: 24---373------\n",
      "129\n",
      "8215\n",
      "Current user: 25---864------\n",
      "129\n",
      "8215\n",
      "Current user: 26---222------\n",
      "129\n",
      "8215\n",
      "Current user: 27---299------\n",
      "129\n",
      "8215\n",
      "Current user: 28---606------\n",
      "129\n",
      "8215\n",
      "Current user: 29---823------\n",
      "129\n",
      "8215\n",
      "Current user: 30---455------\n",
      "129\n",
      "8215\n",
      "Current user: 31---815------\n",
      "129\n",
      "8215\n",
      "Current user: 32---497------\n",
      "129\n",
      "8215\n",
      "Current user: 33---749------\n",
      "129\n",
      "8215\n",
      "Current user: 34---653------\n",
      "129\n",
      "8215\n",
      "Current user: 35---533------\n",
      "129\n",
      "8215\n",
      "Current user: 36---95------\n",
      "129\n",
      "8215\n",
      "Current user: 37---64------\n",
      "129\n",
      "8215\n",
      "Current user: 38---62------\n",
      "129\n",
      "8215\n",
      "Current user: 39---804------\n",
      "129\n",
      "8215\n",
      "Current user: 40---843------\n",
      "129\n",
      "8210\n",
      "Current user: 41---406------\n",
      "129\n",
      "8215\n",
      "Current user: 42---85------\n",
      "129\n",
      "8215\n",
      "Current user: 43---479------\n",
      "129\n",
      "8214\n",
      "Current user: 44---303------\n",
      "129\n",
      "8215\n",
      "Current user: 45---194------\n",
      "129\n",
      "8214\n",
      "Current user: 46---151------\n",
      "129\n",
      "8215\n",
      "Current user: 47---249------\n",
      "129\n",
      "8215\n",
      "Current user: 48---417------\n",
      "129\n",
      "8215\n",
      "Current user: 49---716------\n",
      "129\n",
      "8215\n",
      "Current user: 50---128------\n",
      "129\n",
      "8215\n",
      "Current user: 51---805------\n",
      "129\n",
      "8214\n",
      "Current user: 52---897------\n",
      "129\n",
      "8215\n",
      "Current user: 53---378------\n",
      "129\n",
      "8215\n",
      "Current user: 54---18------\n",
      "129\n",
      "8215\n",
      "Current user: 55---666------\n",
      "129\n",
      "8215\n",
      "Current user: 56---437------\n",
      "129\n",
      "8213\n",
      "Current user: 57---880------\n",
      "129\n",
      "8215\n",
      "Current user: 58---889------\n",
      "129\n",
      "8215\n",
      "Current user: 59---374------\n",
      "129\n",
      "8214\n",
      "Current user: 60---109------\n",
      "129\n",
      "8215\n",
      "Current user: 61---758------\n",
      "129\n",
      "8215\n",
      "Current user: 62---916------\n",
      "129\n",
      "8215\n",
      "Current user: 63---788------\n",
      "129\n",
      "8215\n",
      "Current user: 64---42------\n",
      "129\n",
      "8215\n",
      "Current user: 65---13------\n",
      "129\n",
      "8215\n",
      "Current user: 66---347------\n",
      "129\n",
      "8215\n",
      "Current user: 67---454------\n",
      "129\n",
      "8215\n",
      "Current user: 68---301------\n",
      "129\n",
      "8215\n",
      "Current user: 69---648------\n",
      "129\n",
      "8215\n",
      "Current user: 70---450------\n",
      "129\n",
      "8215\n",
      "Current user: 71---399------\n",
      "129\n",
      "8213\n",
      "Current user: 72---429------\n",
      "129\n",
      "8215\n",
      "Current user: 73---457------\n",
      "129\n",
      "8215\n",
      "Current user: 74---622------\n",
      "129\n",
      "8215\n",
      "Current user: 75---592------\n",
      "129\n",
      "8215\n",
      "Current user: 76---854------\n",
      "129\n",
      "8215\n",
      "Current user: 77---178------\n",
      "129\n",
      "8215\n",
      "Current user: 78---6------\n",
      "129\n",
      "8215\n",
      "Current user: 79---487------\n",
      "129\n",
      "8215\n",
      "Current user: 80---727------\n",
      "129\n",
      "8215\n",
      "Current user: 81---500------\n",
      "129\n",
      "8215\n",
      "Current user: 82---846------\n",
      "129\n",
      "8215\n",
      "Current user: 83---201------\n",
      "129\n",
      "8215\n",
      "Current user: 84---435------\n",
      "129\n",
      "8215\n",
      "Current user: 85---198------\n",
      "129\n",
      "8215\n",
      "Current user: 86---524------\n",
      "129\n",
      "8214\n",
      "Current user: 87---311------\n",
      "129\n",
      "8215\n",
      "Current user: 88---344------\n",
      "129\n",
      "8215\n",
      "Current user: 89---345------\n",
      "129\n",
      "8215\n",
      "Current user: 90---328------\n",
      "129\n",
      "8215\n",
      "Current user: 91---405------\n",
      "129\n",
      "8215\n",
      "Current user: 92---561------\n",
      "129\n",
      "8215\n",
      "Current user: 93---271------\n",
      "129\n",
      "8214\n",
      "Current user: 94---94------\n",
      "129\n",
      "8215\n",
      "Current user: 95---537------\n",
      "129\n",
      "8215\n",
      "Current user: 96---305------\n",
      "129\n",
      "8215\n",
      "Current user: 97---387------\n",
      "129\n",
      "8215\n",
      "Current user: 98---892------\n",
      "129\n",
      "8215\n",
      "Current user: 99---896------\n",
      "129\n",
      "8215\n",
      "Current user: 100---655------\n",
      "129\n",
      "8214\n",
      "Current user: 101---308------\n",
      "129\n",
      "8215\n",
      "Current user: 102---327------\n",
      "129\n",
      "8215\n",
      "Current user: 103---393------\n",
      "129\n",
      "8215\n",
      "Current user: 104---474------\n",
      "129\n",
      "8215\n",
      "Current user: 105---144------\n",
      "129\n",
      "8215\n",
      "Current user: 106---59------\n",
      "129\n",
      "8215\n",
      "Current user: 107---682------\n",
      "129\n",
      "8215\n",
      "Current user: 108---774------\n",
      "129\n",
      "8210\n",
      "Current user: 109---747------\n",
      "129\n",
      "8215\n",
      "Current user: 110---293------\n",
      "129\n",
      "8215\n",
      "Current user: 111---184------\n",
      "129\n",
      "8215\n",
      "Current user: 112---588------\n",
      "129\n",
      "8215\n",
      "Current user: 113---313------\n",
      "129\n",
      "8215\n",
      "Current user: 114---339------\n",
      "129\n",
      "8215\n",
      "Current user: 115---234------\n",
      "129\n",
      "8215\n",
      "Current user: 116---660------\n",
      "129\n",
      "8213\n",
      "Current user: 117---488------\n",
      "129\n",
      "8215\n",
      "Current user: 118---618------\n",
      "129\n",
      "8215\n",
      "Current user: 119---7------\n",
      "129\n",
      "8215\n",
      "Current user: 120---650------\n",
      "129\n",
      "8215\n",
      "Current user: 121---90------\n",
      "129\n",
      "8214\n",
      "Current user: 122---643------\n",
      "129\n",
      "8215\n",
      "Current user: 123---269------\n",
      "129\n",
      "8214\n",
      "Current user: 124---363------\n",
      "129\n",
      "8215\n",
      "Current user: 125---334------\n",
      "129\n",
      "8215\n",
      "Current user: 126---883------\n",
      "129\n",
      "8215\n",
      "Current user: 127---280------\n",
      "129\n",
      "8214\n",
      "Current user: 128---796------\n",
      "129\n",
      "8215\n",
      "Current user: 129---551------\n",
      "129\n",
      "8215\n"
     ]
    }
   ],
   "source": [
    "results = list()\n",
    "i = 1\n",
    "for user in users:\n",
    "    print(\"Current user: \" + str(i) + \"---\" + str(user) + \"------\")\n",
    "    results.append(main_process(user, items_eval))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results_ev = list()\n",
    "for k in range(K):\n",
    "    list_k = list()\n",
    "    for measure in range(len(MEASURES)):\n",
    "        my_pd_metric = [df[k][measure] for df in results] \n",
    "        list_k.append(pd.concat(my_pd_metric))\n",
    "    metrics_results_ev.append(list_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_results = [[calculateScoreResults(metrics_results_ev[k][MEASURES.index(measure)]) for measure in MEASURES] for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[None, None, None, None, None, None, None, None],\n",
       " [None, None, None, None, None, None, None, None],\n",
       " [None, None, None, None, None, None, None, None]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[write_results_file(\"results/user_weighted_vot_50.csv\", metrics_results[k][MEASURES.index(measure)], range_K[k], measure) for measure in MEASURES] for k in range(K)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
